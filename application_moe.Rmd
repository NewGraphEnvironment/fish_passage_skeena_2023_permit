---
title: "Fish Permit Application"
author: "Al Irvine"
output:
  pagedown::html_letter:
    self_contained: true
    css: ["style-pagedown.css", "default", "letter"]
links-to-footnotes: false
paged-footnotes: false
# uncomment this line to produce HTML and PDF in RStudio:
knit: pagedown::chrome_print
---

![logo](fig/nge-full_black.png){.logo} 


 

<br>

::: from
Al Irvine  
New Graph Environment Ltd.  
al@newgraphenvironment   
250-777-1518  
Date: `r format(Sys.Date(), "%Y-%m-%d")` 
:::


Ministry of Environment  
and
Fisheries and Oceans Canada



<br>

**Re: Fish Permit Application**

<br>

```{r setup, include = TRUE, echo =FALSE, message=FALSE, warning=FALSE}
# gitbook_on <- TRUE
gitbook_on <- FALSE  ##we just need turn  this on and off to switch between gitbook and pdf via paged.js


knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, dpi=60, out.width = "100%")
options(scipen=999)
options(knitr.kable.NA = '--') #'--'
options(knitr.kable.NAN = '--')

source('R/packages.R')
source('R/functions.R')

name_project <- 'skeena_2023'
name_repo <- 'fish_passage_skeena_2023_permit'

link_repo <- paste0('https://newgraphenvironment.github.io/', name_repo, '/')
link_kml <- paste0('https://github.com/NewGraphEnvironment/', name_repo, '/raw/main/docs/sites_', name_project, '_', format(Sys.Date(), '%Y%m%d'), '_kml.zip')
```

```{r settings-gitbook, eval= gitbook_on}
photo_width <- "100%"
font_set <- 11

```

```{r settings-paged-html, eval= identical(gitbook_on, FALSE)}
photo_width <- "80%"
font_set <- 8
```

A summary of sites to be potentially assessed is included as Tables \@ref(tab:tab-sites1) - \@ref(tab:tab-sites2),  details of fish species potentially encountered is presented in  Table \@ref(tab:tab-fish) and an overview map displaying potential sample locations is included as Figure 1. A kml file of the sites is included as an attachment to the application and can also be downloaded [from here at this link](`r knitr::asis_output(link_kml)`).  Please note that there is an extensive amount of information contained in the kml file (accessed by clicking on sites) including brief summaries of background reporting data (when available).

<br>

This work is a multi-year collaboration of many groups and an initiative of the Society for Ecosystem Restoration Northern BC. It includes planning, implementation and monitoring of fish passage and other aquatic habitat restoration. 

<br>

Funding for the project is through the Habitat Trust Conservation Foundation, Ministry of Transportation and Infrastructure and the Provincial Fish Passage Technical Working Group.  Al Irvine, R.P.Bio and Mateo Winterschiedt from New Graph Environment Ltd. are leading the fieldwork with field and office collaboration with teams from the Office of Wet'suwet'en (contact Mike Ridsdale - mike.ridsdale@wetsuweten.com or Dave Dewit - david.dewit@wetsuweten.com), Gitskan Watershed Authorities (contact Alicia Fernando - afernando@gitksanwatershed.com ) and Gitsxan Environmental Services (contact Chaz Ware - chaz.ware@gitxsanbusiness.com ). Past reports are below:

- https://newgraphenvironment.github.io/fish_passage_bulkley_2020_reporting/
- https://newgraphenvironment.github.io/fish_passage_skeena_2021_reporting/
- https://newgraphenvironment.github.io/fish_passage_bulkley_2022_reporting/
- https://newgraphenvironment.github.io/fish_passage_skeena_2022_reporting/
- https://newgraphenvironment.github.io/fish_passage_moti_2022_reporting/

<br>

Rationale for sampling is to inform fish presence/absence, species composition/density, abundance estimates,  movement, growth, and survival as part of habitat confirmations and effectiveness monitoring related to fish passage restoration at barrier culverts.  Although methods are evolving they are based on those in the [Fish Passage Technical Working Group Phase 2 protocol](https://www2.gov.bc.ca/gov/content/environment/natural-resource-stewardship/land-based-investment/investment-categories/fish-passage). Presence/absence of fish, species composition/abundance, distribution limits, fish health and fish movement can be useful for prioritizing which crossings are a best fit for fish passage restoration and inform  effectiveness monitoring.  

<br>

Sampling is proposed at streams included in Tables \@ref(tab:tab-sites1) - \@ref(tab:tab-sites2) where we will be performing habitat confirmations and follow up site visits related to past habitat confirmations/fish passage remediations.  

<br>

Sampling methodologies will be dependent on the site, fish species suspected, type of habitat encountered, risks to aquatic organisms potentially present and ongoing communications.  Sampling methods may include minnowtrapping, electrofishing, and dipnetting upstream and downstream of barrier culvert locations. 

<br>

As part of this permit application we are proposing tagging.  Our study plan is (when time allows and PIT tagging is expected to increase our state of knowledge about the subject system) to electrofish small sites both upstream and downstream of priority culvert "barrier" sites and insert biomark APT12 PIT tags into the body cavity of all fish captured over 60mm.  Fish location (UTM), length and weight will also be collected.  In addition to providing information on abundance upstream and downstream of potential culvert restoration sites, the study will also provide baseline information for monitoring programs to document fish movement, growth and survival at these sites over multi-year timeframes and evaluate if 

1. fish are moving into restored areas, 
2. through sites where stream crossing structures (culverts) likely causing connectivity issues before any remediation is conducted and to 
3. evaluate if productivity of the systems are increasing following bridge installation and/or if fish are moving upstream/downstream of where replaced/removed structures are located).  

<br>

It should be noted that we are not necessarily tagging all fish we capture - however there are sites in which this may be helpful for baseline and ongoing monitoring.  In these situations as we wish to tag all species of interest (stream dependent) over 60mm in each site sampled we would like to apply for a permit allowing a maximum of 720 fish with a maximum of 120 fish/stream.  Although we are requesting a maximum of 120 fish/stream, we have listed 120fish of each species per stream because we will not know the species composition of the sites until the sampling occurs. It should be noted however that we will not tag more than 60 fish of one species within each stream (30 upstream and 30 downstream of road/stream crossings).


<br>


Please note that the sampling will be completed before October 31 (end of August till mid-September) however the end-date of the sampling period is listed as Dec 31 on the application to allow time outside of the busy field season for the data to be processed, QA'd and organized so that required reporting can be as informative as possible when submitted. 

<br>

Please do not hesitate to contact me if you need more information or have any questions or concerns.



![signature](/Users/airvine/Library/CloudStorage/OneDrive-Personal/Admin/Al_Sig.jpg){width=50%}  
Al Irvine, R.P.Bio 

```{r pull-db}
##pull out what we need from the database
# see usethis::edit_r_environ

conn <- DBI::dbConnect(
  RPostgres::Postgres(),
  dbname = Sys.getenv('PG_DB_DEV'),
  host = Sys.getenv('PG_HOST_DEV'),
  port = 5432,
  user = Sys.getenv('PG_USER_DEV'),
  password = Sys.getenv('PG_PASS_DEV')
)

# grab the crossings data from the digital ocean database
query = "SELECT * FROM bcfishpass.crossings WHERE watershed_group_code IN ('MORR', 'BULK', 'ZYMO', 'KISP')"

sites <- sf::st_read(conn, 
                     query = query)

sites_pull <- c(
  #mcDopwell#
  58159,
  #Nanika trib resurvey#
  198008,
  #thompson#
  123377,
  #glen vowell#
  198217, 
  #sterrit#
  198225, 
  # gramaphone#
  58067,
  #sandstone#
  8530,
  ##zymoetz promising#
  8543,
  ##zymoetz promising - SK point downstream#
  8547,
  ##zymoetz promising#
  8454,
  ##helps#
  124500,
  # trib to buck#
  197640,
  #peacock#
  197962,
  #trib to owen 20km#
  197379,
  #trib to owen other side#
  197378,
  #riddeck#
  197740,
  #trib to owen promissing same side - potential barrier - nice gravels#
  198060,
  #trib to owen promissing same side - 70cm drop upstream but that may not matter - good flow. nice stream - outlet drop. sample#
  197365,
  #trib to McBride#
  1024702220,
  #trib to McBride#
  1014000666,
  #stock#
  195943,
  #trib to tagit
  197949,
  #trib to Lamprey#
  198064
  )

sites_for_review <- sites %>% 
  filter(stream_crossing_id %in% c(sites_pull))

# grab the watershed codes
wscodes <- DBI::dbGetQuery(conn,
                      "SELECT DISTINCT ON (aggregated_crossings_id)
a.aggregated_crossings_id,
a.linear_feature_id,
a.watershed_group_code,
b.watershed_code_50k,
substring(b.watershed_code_50k from 1 for 3)
||'-'||substring(b.watershed_code_50k from 4 for 6)
||'-'||substring(b.watershed_code_50k from 10 for 5)
||'-'||substring(b.watershed_code_50k from 15 for 5)
||'-'||substring(b.watershed_code_50k from 20 for 4)
||'-'||substring(b.watershed_code_50k from 24 for 4)
||'-'||substring(b.watershed_code_50k from 28 for 3)
||'-'||substring(b.watershed_code_50k from 31 for 3)
||'-'||substring(b.watershed_code_50k from 34 for 3)
||'-'||substring(b.watershed_code_50k from 37 for 3)
||'-'||substring(b.watershed_code_50k from 40 for 3)
||'-'||substring(b.watershed_code_50k from 43 for 3) as watershed_code_50k_parsed,
b.blue_line_key_20k,
b.watershed_key_20k,
b.blue_line_key_50k,
b.watershed_key_50k,
b.match_type
FROM bcfishpass.crossings a
LEFT OUTER JOIN whse_basemapping.fwa_streams_20k_50k b
ON a.linear_feature_id = b.linear_feature_id_20k
ORDER BY a.aggregated_crossings_id, b.match_type;"
)   %>% 
  filter(aggregated_crossings_id %in% c(sites_for_review %>% 
                                          pull(aggregated_crossings_id))) |> 
  rename(id = aggregated_crossings_id)

ids <- sites_for_review %>% pull(aggregated_crossings_id)

# annoyingly we are missing the upstream species list for our crossings because of the column type and issues getting
# it to the remote db.  therefore we need to grab and join

sql <- glue::glue_sql("SELECT c.aggregated_crossings_id, c.observedspp_upstr, localcode_ltree FROM bcfishpass.crossings c WHERE c.aggregated_crossings_id IN ({ids*})",
                      .con = conn)

query <- DBI::dbSendQuery(conn, sql)
df <- DBI::dbFetch(query)
dbClearResult(query)
                      


```

```{r combine}
# make a table with the watershed codes, stream name, fish species
table_wsc_prep1 <- left_join(
  sites_for_review %>% 
    select(id = aggregated_crossings_id, gnis_stream_name, stream_name = pscis_stream_name),
  wscodes %>% select(id, watershed_code_50k_parsed),
  by = 'id'
) %>%  
  # sf::st_drop_geometry() |> 
  arrange(id) %>%  
  mutate(stream_name = case_when(
    is.na(stream_name) ~ gnis_stream_name,
    T ~ stream_name
  )) 


# add in the species codes
table_wsc <- left_join(
  table_wsc_prep1,
  
  df %>% 
    rename(id = aggregated_crossings_id),
  
  by = 'id'
) %>% 
  select(id, 
         stream_name, 
         observedspp_upstr, 
         wsc_code = watershed_code_50k_parsed,
         localcode_ltree) %>% 
  #sub in the localcode when we don't have 1:50000
  mutate(localcode_ltree = as.character(localcode_ltree),
         wsc_code = case_when(is.na(wsc_code) ~ localcode_ltree,
                              T ~ wsc_code)) %>% 
  select(-localcode_ltree)

# make a gpx file table


# join all the wsc and crossings tables together
table_sites <- left_join(
  sites_for_review |> 
  select(id = aggregated_crossings_id, 
         bt_network_km,
         bt_spawning_km,
         bt_rearing_km,
         utm_easting,
         utm_northing,
         mapsheet = dbm_mof_50k_grid,
         watershed_group_code,
         pscis_assessment_comment) |> 
  arrange(id),
 
   table_wsc |> sf::st_drop_geometry(),
  
  by = 'id' 
) |> 
  sf::st_transform(crs = 4326) %>% 
  # we had to us the old magritter pipe here!
  mutate(long = sf::st_coordinates(.)[,1],
         lat = sf::st_coordinates(.)[,2]) %>% 
  select(-utm_easting, -utm_northing) %>% 
  distinct(id, .keep_all = T) 

```

```{r gpx}

dir.create('mapping')

#make a gpx file for loading into the gps'
sites_for_review |> 
  mutate(desc = 'bt_rearing_km',
         # make a name that tells a story so we see it on the gps
         name = paste0(aggregated_crossings_id)) %>% 
  # drop z dimension
  st_zm() %>% 
  distinct(aggregated_crossings_id, .keep_all = T) %>%
  rename(geometry = geom) %>% 
  select(name, desc, geometry) %>% 
  sf::st_transform(crs = 4326) %>% 
  write_sf(dsn = paste0("mapping/sites_", name_project, '_', format(Sys.Date(), "%Y%m%d"), ".gpx"), driver="GPX",
           dataset_options="GPX_USE_EXTENSIONS=yes", delete_dsn = TRUE)

```

```{r kml}
##make a kml for adding to the georef pdf and sharing with stakeholders

df <- table_sites %>%
  distinct(id, .keep_all = T) %>% 
  # can build a more descriptive name here but keeping simple
  mutate(name = id) %>% 
  # mutate(name = paste0(id, '_', source, '_', followup_priority)) %>% 
  mutate(shape = 'http://maps.google.com/mapfiles/kml/paddle/red-blank.png',
         color = 'red',
         label = NA_character_) %>%
                           # color = plotKML::col2kml(color)) %>%
           dplyr::group_split(id) %>% 
           purrr::map(fpr::fpr_make_html_tbl) %>%
           dplyr::bind_rows() %>%  # drop z dimension
           st_zm()  


sites_kml <- as(df, 'Spatial')

shape = "http://maps.google.com/mapfiles/kml/pal2/icon18.png"



kml_open(paste0("mapping/sites_", name_project, '_', format(Sys.Date(), "%Y%m%d"), '.kml'))
kml_layer(sites_kml, colour = '#ff7f00', shape = sites_kml$shape, labels = sites_kml$name, 
          html.table = sites_kml$html_tbl,
          z.scale = 2, LabelScale = 1, size = 1.5)  ##I don't see the label
kml_close(paste0("mapping/sites_", name_project, '_', format(Sys.Date(), "%Y%m%d"), '.kml'))

##now we will zip up the kml files in the data folder and rename with kmz
files_to_zip <- paste0("mapping/", list.files(path = "mapping/", pattern = "\\.kml$"))  ##this will zip all kmls in file so watch out
zip::zipr(paste0("docs/sites_", name_project, '_', format(Sys.Date(), "%Y%m%d"), '_kml.zip'), files = files_to_zip)  ##it does not work to zip to kmz!!


```

<br>


```{r map, fig.cap= 'Location of potential sample sites.', eval = T}


##register google key defined in 'R/private_info.R' file
# ggmap::register_google(key = google_api_key)
ggmap::register_google(key = Sys.getenv('GOOG_API_KEY'))

#define the area of the base map by using a bounding box 
mybasemap <- ggmap::get_map(location = c(left = table_sites %>% pull(long) %>% min()-0.01, 
                                    bottom = table_sites %>% pull(lat) %>% min()-0.01,
                                    right = table_sites %>% pull(long) %>% max()+0.01,
                                    top = table_sites %>% pull(lat) %>% max()+0.01),
                     source = "google",
                     zoom = 8,
                    maptype = "hybrid")



#define the area of the base map by using the middle. 
# mybasemap <- ggmap::get_map(location = c(lon = table_sites %>% pull(long) %>% mean(),
#                                          lat = table_sites %>% pull(lat) %>% mean())
#                             source = "google",
#                             zoom = "auto",
#                             maptype = "hybrid")

mymap <- ggmap::ggmap(mybasemap) + 
  geom_point(data = table_sites , 
             aes(x = long, y = lat,
                 color = 'red'),
             show.legend = F) +
  ggplot2::geom_text(data = table_sites,
                            aes(x = long,
                                y = lat,
                                label = id),
                     color = 'white',
                     fontface = "bold",
                      size = 2,
                      hjust = -0.5)
  # ggrepel::geom_label_repel(data = table_sites,
  #                           aes(x = long, y = lat, label = id),
  #                               box.padding = 2, point.padding = 0.5)
  # ggsflabel::geom_sf_label(data = table_sites,
  #                          aes(x = long, y = lat, label = id),
  #                          # force = 100,
  #                          nudge_x = -2)

mymap
```


\newpage

"

```{r tab-sites1, eval = T}
# build a table with overall details
# there is something wrong with kableextra that is causing issues with the col_width_min function
# this works but any changes (increase number, add columns etc. breaks it)

table_sites %>% 
  # filter(id %in% sites_tagging) %>% 
  sf::st_drop_geometry() %>% 
  arrange(id) %>% 
  select(id, 
         stream_name, wsc_code, lat, long, watershed_group_code) %>% 
    # pscis names for copper trib is incorrectly stated as copper
  mutate(stream_name = case_when(stream_name == 'Copper' ~ 'Tributary to Zymoetz River',
                                 T ~ stream_name)) %>% 
  knitr::kable(caption = 'Potential sampling locations.',
               footnote_text = 'Watershed codes with periods vs slashes are 1:20,000') %>% 
  kableExtra::kable_styling(c("condensed", "responsive"),
                              full_width = T,
                              font_size = 8)
  # fpr::fpr_kable(caption_text = 'Potential sample locations.', 
  #                footnote_text = '*Up to 6 sites to be sampled with max 150 fish tagged at each site',
  #                # col_width_min = 6,
  #                scroll = F) 
  # knitr::kable(caption = 'Potential sample locations.', booktabs = T) %>%
  # # kableExtra::kable_styling(c("condensed"),
  # #                           full_width = T,
  # #                           font_size = font_set) %>%
  # # kableExtra::column_spec(column = c(3,4,7), width_min = '1.0in') %>%
  # kableExtra::column_spec(column = c(7), width_max = '2.0in')
```

<br>


```{r tab-sites2, eval = T}

#`r if(gitbook_on){knitr::asis_output("<br>")} else knitr::asis_output("<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>")`
# build a table with overall details

# there is something wrong with kableextra that is causing issues with the col_width_min function
# this works but any changes (increase number, add columns etc. breaks it)

table_sites %>% 
  sf::st_drop_geometry() %>% 
  arrange(id) %>% 
  mutate(fish_tags = 120) %>% 
  select(id, 
         stream_name, 
         sp_upstr = observedspp_upstr,
         fish_tags) %>% 
  # pscis names for copper trib is incorrectly stated as copper
  mutate(stream_name = case_when(stream_name == 'Copper' ~ 'Tributary to Zymoetz River',
                                 T ~ stream_name)) %>% 
  # filter(id %in% sites_tagging) %>% 
  knitr::kable(caption = 'Potential sample site details.') %>% 
  kableExtra::kable_styling(c("condensed", "responsive"),
                            full_width = T,
                            font_size = 8) %>% 
  kableExtra::column_spec(column = 3, width_min = '0.75in')
# fpr::fpr_kable(caption_text = 'Potential sample locations.', 
#                footnote_text = '*Up to 6 sites to be sampled with max 150 fish tagged at each site',
#                # col_width_min = 6,
#                scroll = F) 
# knitr::kable(caption = 'Potential sample locations.', booktabs = T) %>%
# # kableExtra::kable_styling(c("condensed"),
# #                           full_width = T,
# #                           font_size = font_set) %>%
# # kableExtra::column_spec(column = c(3,4,7), width_min = '1.0in') %>%
# kableExtra::column_spec(column = c(7), width_max = '2.0in')
```


\newpage

"




```{r tab-fish}
tab_fish <- readr::read_csv(paste0(getwd(), '/fig/fiss_species_table.csv'))

tab_fish %>% 
  select(`Scientific Name`:`SARA`) %>% 
  my_kable(caption_text = 'Fish species recorded in the region.')


```



